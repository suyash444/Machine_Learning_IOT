{"cells":[{"cell_type":"code","metadata":{"source_hash":"3c3773f4","execution_start":1704340771772,"execution_millis":6,"deepnote_to_be_reexecuted":false,"cell_id":"6f78f51e11874cf9b2474314bb4e16b9","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nyes_no_train_ds = tf.data.Dataset.list_files('/tmp/yn-train/*')\nyes_no_test_ds = tf.data.Dataset.list_files('/tmp/yn-test/*')","block_group":"6f78f51e11874cf9b2474314bb4e16b9","execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"89b335512bc641c28901895ccbff213c","deepnote_cell_type":"text-cell-h1"},"source":"# Pre-processing & Training Hyper-parameters","block_group":"397e290f90ca485f8e08102c7d8ba361"},{"cell_type":"code","metadata":{"source_hash":"e8f8ba28","execution_start":1704340774825,"execution_millis":12,"deepnote_to_be_reexecuted":false,"cell_id":"69bacdb8d3b149d78b62cf23d77f74cc","deepnote_cell_type":"code"},"source":"PREPROCESSING_ARGS = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.016,\n    'frame_step_in_s': 0.012,\n    'num_mel_bins': 10,\n    'lower_frequency': 20,\n    'upper_frequency': 4000,\n    'num_coefficients': 30,\n}\n\nTRAINING_ARGS = {\n    'batch_size': 30,\n    'initial_learning_rate': 0.005,\n    'end_learning_rate': 1.e-5,\n    'epochs': 20\n}\nfinal_sparsity = 0.70","block_group":"e756345a64d141cbb054dcaa19fa70be","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"a84e8c8d","execution_start":1704340779432,"execution_millis":622,"deepnote_to_be_reexecuted":false,"cell_id":"80aec728859349509d89e1ef69188fc0","deepnote_cell_type":"code"},"source":"from preprocessing import LABELS\nfrom preprocessing import AudioReader\nfrom preprocessing import MFCC\n\n\naudio_reader = AudioReader(tf.int16, 16000)\nmfcc_processor = MFCC(**PREPROCESSING_ARGS)\n\ndef prepare_for_training(feature, label):\n    feature = tf.expand_dims(feature, -1)\n    label_id = tf.argmax(label == LABELS)\n\n    return feature, label_id\n\n\nbatch_size = TRAINING_ARGS['batch_size']\nepochs = TRAINING_ARGS['epochs']\n\ntrain_ds = (yes_no_train_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mfcc_processor.get_mfccs_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size)\n            .cache())\n\ntest_ds = (yes_no_test_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mfcc_processor.get_mfccs_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size))","block_group":"1d936c1512244175a52a65ae348cb8a7","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"9dead3aa","execution_start":1704340784993,"execution_millis":322,"deepnote_to_be_reexecuted":false,"cell_id":"db2e917536c249d6be3b10b0cda2a975","deepnote_cell_type":"code"},"source":"for example_batch, example_labels in train_ds.take(1):\n  print('Batch Shape:', example_batch.shape)\n  print('Data Shape:', example_batch.shape[1:])\n  print('Labels:', example_labels)","block_group":"3c2da75ce8714fb6931f75ee191b54a1","execution_count":15,"outputs":[{"name":"stdout","text":"Batch Shape: (30, 83, 10, 1)\nData Shape: (83, 10, 1)\nLabels: tf.Tensor([0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1], shape=(30,), dtype=int64)\n2024-01-04 03:59:45.297888: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"359e93e2","execution_start":1704340787888,"execution_millis":150,"deepnote_to_be_reexecuted":false,"cell_id":"3a25c3dd35364dcf8bc8a247f0108bb5","deepnote_cell_type":"code"},"source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    tf.keras.layers.Conv2D(filters=32, kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(units=len(LABELS)),\n    tf.keras.layers.Softmax()\n])","block_group":"7505894fc8ea4d00b549b6f0c28de572","execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5258eeb7d8b14ae9970444dc65c270e8","deepnote_cell_type":"text-cell-h1"},"source":"# SETUP MAGNITUDE BASED WEIGHT PRUNING","block_group":"f323d51f8f0243c88bcd5f8765148cb4"},{"cell_type":"code","metadata":{"source_hash":"d9334abb","execution_start":1704340791115,"execution_millis":259,"deepnote_to_be_reexecuted":false,"cell_id":"72fc5d1448e047198289e0bd0afc5a52","deepnote_cell_type":"code"},"source":"import tensorflow_model_optimization as tfmot\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\nbegin_step = int(len(train_ds) * epochs * 0.2)\nend_step = int(len(train_ds) * epochs)\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.20,\n        final_sparsity=final_sparsity,\n        begin_step=begin_step,\n        end_step=end_step\n    )\n}\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)","block_group":"1502be82981d4ae19a8a4cf1c9937b48","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"59efc34f","execution_start":1704340794270,"execution_millis":143,"deepnote_to_be_reexecuted":false,"cell_id":"bc1c5166091841d28cbea35c7796409e","deepnote_cell_type":"code"},"source":"model_for_pruning.summary()","block_group":"93a61013161646c694889e1e04897f2f","execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d  (None, 41, 4, 32)         578       \n _4 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 41, 4, 32)         129       \n normalization_4 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 41, 4, 32)         1         \n 4 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 41, 4, 16)         9218      \n _5 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 41, 4, 16)         65        \n normalization_5 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 41, 4, 16)         1         \n 5 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 41, 4, 16)         4610      \n _6 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 41, 4, 16)         65        \n normalization_6 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 41, 4, 16)         1         \n 6 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 41, 4, 16)         4610      \n _7 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 41, 4, 16)         65        \n normalization_7 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 41, 4, 16)         1         \n 7 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_global  (None, 16)                1         \n _average_pooling2d_1 (Prun                                      \n eLowMagnitude)                                                  \n                                                                 \n prune_low_magnitude_dense_  (None, 2)                 68        \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_softma  (None, 2)                 1         \n x_1 (PruneLowMagnitude)                                         \n                                                                 \n=================================================================\nTotal params: 19414 (75.89 KB)\nTrainable params: 9698 (37.88 KB)\nNon-trainable params: 9716 (38.01 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"5c3dcb84","execution_start":1704340797507,"execution_millis":71296,"deepnote_to_be_reexecuted":false,"cell_id":"814b42cbc6b946b797d6c4b974aaf538","deepnote_cell_type":"code"},"source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\ninitial_learning_rate = TRAINING_ARGS['initial_learning_rate']\nend_learning_rate = TRAINING_ARGS['end_learning_rate']\n\nlinear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=initial_learning_rate,\n    end_learning_rate=end_learning_rate,\n    decay_steps=len(train_ds) * epochs,\n)\noptimizer = tf.optimizers.Adam(learning_rate=linear_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\ncallbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n\nmodel_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\nhistory = model_for_pruning.fit(train_ds, epochs=epochs,callbacks=callbacks)","block_group":"00debad9b2d040cc8cdb1cdb6b010c71","execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/20\n54/54 [==============================] - 12s 119ms/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8587\nEpoch 2/20\n54/54 [==============================] - 3s 59ms/step - loss: 0.2151 - sparse_categorical_accuracy: 0.9287\nEpoch 3/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9525\nEpoch 4/20\n54/54 [==============================] - 3s 56ms/step - loss: 0.1136 - sparse_categorical_accuracy: 0.9681\nEpoch 5/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9737\nEpoch 6/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9787\nEpoch 7/20\n54/54 [==============================] - 3s 56ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9850\nEpoch 8/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9881\nEpoch 9/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9894\nEpoch 10/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9906\nEpoch 11/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9931\nEpoch 12/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0372 - sparse_categorical_accuracy: 0.9937\nEpoch 13/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9956\nEpoch 14/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9850\nEpoch 15/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9931\nEpoch 16/20\n54/54 [==============================] - 3s 53ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9925\nEpoch 17/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9937\nEpoch 18/20\n54/54 [==============================] - 3s 56ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9950\nEpoch 19/20\n54/54 [==============================] - 3s 55ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9969\nEpoch 20/20\n54/54 [==============================] - 3s 56ms/step - loss: 0.0246 - sparse_categorical_accuracy: 0.9969\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"ddc77961","execution_start":1704340880874,"execution_millis":1246,"deepnote_to_be_reexecuted":false,"cell_id":"562e10896d8a4792b9abe7829ace7568","deepnote_cell_type":"code"},"source":"test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)","block_group":"296049d1f7dc4e3b8000e0df08ede376","execution_count":20,"outputs":[{"name":"stdout","text":"7/7 [==============================] - 1s 69ms/step - loss: 0.0390 - sparse_categorical_accuracy: 0.9900\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"6796ed00","execution_start":1704340887404,"execution_millis":9,"deepnote_to_be_reexecuted":false,"cell_id":"9d96580263e7451ab80d8a3d4819741e","deepnote_cell_type":"code"},"source":"training_loss = history.history['loss'][-1]\ntraining_accuracy = history.history['sparse_categorical_accuracy'][-1]\n\nprint(f'Training Loss: {training_loss:.4f}')\nprint(f'Training Accuracy: {training_accuracy*100.:.2f}%')\nprint()\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy*100.:.2f}%')","block_group":"1fa848e967e44b8ca81cfc9162540f6a","execution_count":21,"outputs":[{"name":"stdout","text":"Training Loss: 0.0246\nTraining Accuracy: 99.69%\n\nTest Loss: 0.0390\nTest Accuracy: 99.00%\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"ab67293","execution_start":1704340893443,"execution_millis":20,"deepnote_to_be_reexecuted":false,"cell_id":"37c55d6826fd4615ba0622dfd76c00da","deepnote_cell_type":"code"},"source":"import numpy as np\n\n\nfor layer in model_for_pruning.layers:\n    if isinstance(layer, tf.keras.layers.Wrapper):\n        weights = layer.trainable_weights\n    else:\n        weights = layer.weights\n    for weight in weights:        \n        weight_size = weight.numpy().size\n        zero_num = np.count_nonzero(weight == 0)\n        print(\n            f'{weight.name}: {zero_num/weight_size:.2%} sparsity ',\n            f'({zero_num}/{weight_size})',\n        )","block_group":"fcbdc69a0924438c830f67aa96f6d9ad","execution_count":22,"outputs":[{"name":"stdout","text":"conv2d_4/kernel:0: 70.14% sparsity  (202/288)\nbatch_normalization_4/gamma:0: 0.00% sparsity  (0/32)\nbatch_normalization_4/beta:0: 0.00% sparsity  (0/32)\nconv2d_5/kernel:0: 69.99% sparsity  (3225/4608)\nbatch_normalization_5/gamma:0: 0.00% sparsity  (0/16)\nbatch_normalization_5/beta:0: 0.00% sparsity  (0/16)\nconv2d_6/kernel:0: 69.97% sparsity  (1612/2304)\nbatch_normalization_6/gamma:0: 0.00% sparsity  (0/16)\nbatch_normalization_6/beta:0: 0.00% sparsity  (0/16)\nconv2d_7/kernel:0: 69.97% sparsity  (1612/2304)\nbatch_normalization_7/gamma:0: 0.00% sparsity  (0/16)\nbatch_normalization_7/beta:0: 0.00% sparsity  (0/16)\ndense_1/kernel:0: 68.75% sparsity  (22/32)\ndense_1/bias:0: 0.00% sparsity  (0/2)\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f659f3d328204e258f4de9e99b07e59d","deepnote_cell_type":"text-cell-h1"},"source":"# Save The Model","block_group":"b72f6191bdd94afeb94d32f359f704f2"},{"cell_type":"code","metadata":{"source_hash":"ed02f8","execution_start":1704340898101,"execution_millis":6577,"deepnote_to_be_reexecuted":false,"cell_id":"96675546d33d44aea5e47eb18935f77a","deepnote_cell_type":"code"},"source":"import os\nfrom time import time\n\ntimestamp = int(time())\n\nsaved_model_dir = f'./saved_models/{timestamp}'\nif not os.path.exists(saved_model_dir):\n    os.makedirs(saved_model_dir)\nmodel.save(saved_model_dir)","block_group":"2d55bc1d65cd4596aabcb33cc4644677","execution_count":23,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nINFO:tensorflow:Assets written to: ./saved_models/1704340898/assets\nINFO:tensorflow:Assets written to: ./saved_models/1704340898/assets\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":19,"fromCodePoint":0}],"cell_id":"5fc1062449ed47328b76bd260fbebd79","deepnote_cell_type":"text-cell-p"},"source":"Save Hyperparameter","block_group":"c63bb09989da4257b4de537d7983b833"},{"cell_type":"code","metadata":{"source_hash":"2e3bf2cc","execution_start":1704340907385,"execution_millis":259,"deepnote_to_be_reexecuted":false,"cell_id":"97c0127e4eb24a13b298455286aa6835","deepnote_cell_type":"code"},"source":"import pandas as pd\n\noutput_dict = {\n    'timestamp': timestamp,\n    **PREPROCESSING_ARGS,\n    **TRAINING_ARGS,\n    'test_accuracy': test_accuracy,\n    'final_sparsity': final_sparsity\n}\n\ndf = pd.DataFrame([output_dict])\n\noutput_path='./mel_spectrogram_results.csv'\ndf.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)","block_group":"b6f41cec462c4d2c89f9119d680c1888","execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"12ceb537bcb14a28aa9bac7400eee57e","deepnote_cell_type":"text-cell-h1"},"source":"# TFLite Conversion","block_group":"26c0e083e2ea48778049933e94bd2714"},{"cell_type":"code","metadata":{"source_hash":"db0e61c2","execution_start":1704340911708,"execution_millis":6054,"deepnote_to_be_reexecuted":false,"cell_id":"d741e9aeb7a24488822865589d987e92","deepnote_cell_type":"code"},"source":"!ls saved_models","block_group":"5f12265ffc5f4c1d97945b10bc879f15","execution_count":25,"outputs":[{"name":"stdout","text":"1703604642  1704235763\t1704237560  1704238806\t1704339337  1704340898\n1703608656  1704236809\t1704238096  1704239753\t1704340294\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"fe1a35da","execution_start":1704340926695,"execution_millis":21,"deepnote_to_be_reexecuted":false,"cell_id":"b927055dbabe4641bdf555599094eba6","deepnote_cell_type":"code"},"source":"MODEL_NAME = 1704340898","block_group":"02b192d980e144c28614c98f2bab341f","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"d18d3058","execution_start":1704340953627,"execution_millis":4035,"deepnote_to_be_reexecuted":false,"cell_id":"c78709cb4ce14a44a42abd9d3aa257fe","deepnote_cell_type":"code"},"source":"converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models/{MODEL_NAME}')\ntflite_model = converter.convert()","block_group":"12729076f2364574a59da0b1c76ff391","execution_count":28,"outputs":[{"name":"stderr","text":"2024-01-04 04:02:36.313420: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n2024-01-04 04:02:36.313483: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n2024-01-04 04:02:36.579773: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./saved_models/1704340898\n2024-01-04 04:02:36.846891: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n2024-01-04 04:02:36.846944: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./saved_models/1704340898\n2024-01-04 04:02:36.855268: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n2024-01-04 04:02:37.512521: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ./saved_models/1704340898\n2024-01-04 04:02:37.535019: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 955258 microseconds.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"5eb9fb99","execution_start":1704340960814,"execution_millis":6,"deepnote_to_be_reexecuted":false,"cell_id":"93c604725f10400fb5ddf977fdb04eac","deepnote_cell_type":"code"},"source":"tflite_models_dir = './tflite_models'\nif not os.path.exists(tflite_models_dir):\n    os.makedirs(tflite_models_dir)","block_group":"4d2e3808f12c429697827e7c61e815aa","execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"9658f457","execution_start":1704340965333,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"f17f32d69162431d8d0c947e057dcd65","deepnote_cell_type":"code"},"source":"tflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\ntflite_model_name","block_group":"b897fe900a2a41f6b1cd8617acbf21e7","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"'./tflite_models/1704340898.tflite'"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":"90231985","execution_start":1704340975730,"execution_millis":152,"deepnote_to_be_reexecuted":false,"cell_id":"d9e1d021718240b293ce7257ad5199c6","deepnote_cell_type":"code"},"source":"with open(tflite_model_name, 'wb') as fp:\n    fp.write(tflite_model)","block_group":"7a69b60c5b0d4551a6d796e41db85420","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"c060602f","execution_start":1704340979191,"execution_millis":13469,"deepnote_to_be_reexecuted":false,"cell_id":"141180014fe64b8a828a8b7d226e209c","deepnote_cell_type":"code"},"source":"!ls tflite_models","block_group":"93ada9a7b1fc4b38a187d3ebae21caa9","execution_count":32,"outputs":[{"name":"stdout","text":"1703604642.tflite      1704237560.tflite.zip  1704340294.tflite\n1703604642.tflite.zip  1704238096.tflite      1704340294.tflite.zip\n1703608656.tflite      1704238096.tflite.zip  1704340898.tflite\n1703608656.tflite.zip  1704239753.tflite      MODEL_NAME.tflite.zip\n1704236809.tflite      1704239753.tflite.zip  ref_model.tflite\n1704236809.tflite.zip  1704339337.tflite\n1704237560.tflite      1704339337.tflite.zip\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"389ca024c82747b5bb626204b575050b","deepnote_cell_type":"text-cell-h1"},"source":"# Zip File","block_group":"4144b135fec746429216fe26587e506e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b958f5146dd94a6981c99f8ab5ce8cbb","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"296f9fcac73e44f689385323879ab07a"},{"cell_type":"code","metadata":{"source_hash":"dc6884c1","execution_start":1704340997600,"execution_millis":269,"deepnote_to_be_reexecuted":false,"cell_id":"8914a0f47e184dc2ad92439938ccc662","deepnote_cell_type":"code"},"source":"import zipfile\n\nwith zipfile.ZipFile(f'{tflite_model_name}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n    f.write(tflite_model_name)","block_group":"999cb0bd4bea43bdb08fa3855ced7ca7","execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"5b1dc3ca","execution_start":1704341004449,"execution_millis":860,"deepnote_to_be_reexecuted":false,"cell_id":"3f8965ccfdef42fc81aba1f8f447007a","deepnote_cell_type":"code"},"source":"import zipfile\n\nnot_pruned_tflite = os.path.join(tflite_models_dir, '1704340898.tflite')\n\nwith zipfile.ZipFile(f'{not_pruned_tflite}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n    f.write(not_pruned_tflite) ","block_group":"ce45d73010174f12b0e4a236192a6f08","execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b0401260452f4756b03bc6cb7ba36666","deepnote_cell_type":"text-cell-h1"},"source":"# Zipped tflite size","block_group":"50b01f8a36f94749ab3d06c12566225a"},{"cell_type":"code","metadata":{"source_hash":"2fea0ea9","execution_start":1704341015015,"execution_millis":376,"deepnote_to_be_reexecuted":false,"cell_id":"3ed773623a9b429281c91e2fd47c2ced","deepnote_cell_type":"code"},"source":"not_pruned_tflite_size = os.path.getsize(not_pruned_tflite) / 1024.0\ntflite_size = os.path.getsize(tflite_model_name) / 1024.0\nnot_pruned_zipped_size = os.path.getsize(f'{not_pruned_tflite}.zip') / 1024.0\nzipped_size = os.path.getsize(f'{tflite_model_name}.zip') / 1024.0\n\nprint(f'Original tflite size (not pruned model): {tflite_size:.3f} KB')\nprint(f'Original tflite size (pruned model): {tflite_size:.3f} KB')\nprint(f'Zipped tflite size (not pruned model): {not_pruned_zipped_size:.3f} KB')\nprint(f'Zipped tflite size (pruned model): {zipped_size:.3f} KB')\n","block_group":"81f3d7700b7740c08a7419b617ea126f","execution_count":35,"outputs":[{"name":"stdout","text":"Original tflite size (not pruned model): 41.148 KB\nOriginal tflite size (pruned model): 41.148 KB\nZipped tflite size (not pruned model): 16.509 KB\nZipped tflite size (pruned model): 16.509 KB\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"adc016f3a9834db6aa3efe82c1e6b631","deepnote_cell_type":"text-cell-h1"},"source":"# Latency","block_group":"cde4c7ed48a04132a8f7c022932a1832"},{"cell_type":"code","metadata":{"source_hash":"daf65589","execution_start":1704341038123,"execution_millis":3318,"deepnote_to_be_reexecuted":false,"cell_id":"0e86dace06ff4a9c94039389410bf78a","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\nfrom time import time\nfrom preprocessing import MelSpectrogram\n\n# Configuration for Mel Spectrogram\nSPEC_CONFIG = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.04,\n    'frame_step_in_s': 0.02,\n    'num_mel_bins': 40,\n    'lower_frequency': 20,\n    'upper_frequency': 4000,\n}\n\n# Initialize Mel Spectrogram Processor\nmel_spectrogram_generator = MelSpectrogram(**SPEC_CONFIG)\n\n# Load TensorFlow Lite model\nmodel_interpreter = tf.lite.Interpreter(model_path='tflite_models/ref_model.tflite')\nmodel_interpreter.allocate_tensors()\n\n# Get input and output details\nmodel_input_details = model_interpreter.get_input_details()\nmodel_output_details = model_interpreter.get_output_details()\n\n# Generate random audio sample\nrandom_audio_sample = tf.random.normal((16000,))\n\n# List to store latency times\nlatency_times = []\n\n# Measure latency over 100 iterations\nfor _ in range(100):\n    start_time = time()\n\n    # Process audio to log Mel Spectrogram\n    log_mel_spectrogram = mel_spectrogram_generator.get_mel_spec(random_audio_sample)\n    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, 0)\n    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)\n\n    # Run inference\n    model_interpreter.set_tensor(model_input_details[0]['index'], log_mel_spectrogram)\n    model_interpreter.invoke()\n    inference_output = model_interpreter.get_tensor(model_output_details[0]['index'])\n\n    end_time = time()\n\n    # Calculate and store latency\n    latency_times.append(end_time - start_time)\n\n# Calculate median latency\nmedian_latency = np.median(latency_times)\nmedian_latency_ms = 1000 * median_latency\nprint(median_latency_ms)\n","block_group":"804bc017b0bb45bfb84a592d79123ea1","execution_count":36,"outputs":[{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n27.88376808166504\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":"586b589","execution_start":1704341053583,"execution_millis":5751,"deepnote_to_be_reexecuted":false,"cell_id":"6cedb95979fc43a3926fb2eb0ad6ec4f","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nimport numpy as np\nfrom time import time\nfrom preprocessing import MFCC\n\nmfcc_creator = MFCC(**PREPROCESSING_ARGS)\n\n# Load the TensorFlow Lite model\ntflite_model_path = '/work/tflite_models/1704340898.tflite'\nmodel_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\nmodel_interpreter.allocate_tensors()\n\n# Get the input and output details from the model\ninput_info = model_interpreter.get_input_details()\noutput_info = model_interpreter.get_output_details()\n\n# Create a random audio sample\naudio_sample = tf.random.normal((16000,))\n\n# List to hold latency measurements\nlatency_measurements = []\n\n# Measure latency for 100 iterations\nfor _ in range(100):\n    preprocessing_start = time()\n\n    # Generate MFCC features from the audio sample\n    mfcc_features = mfcc_creator.get_mfccs(audio_sample)\n    mfcc_features = tf.expand_dims(mfcc_features, 0)  # Adding batch dimension\n    mfcc_features = tf.expand_dims(mfcc_features, -1) # Adjusting for model input\n\n    # Set the tensor for model inference\n    model_interpreter.set_tensor(input_info[0]['index'], mfcc_features)\n    model_interpreter.invoke()\n\n    # Retrieve the output from the model\n    model_output = model_interpreter.get_tensor(output_info[0]['index'])\n\n    inference_end = time()\n\n    # Calculate and append latency\n    latency_measurements.append(inference_end - preprocessing_start)\n\n# Compute the median latency\nmedian_latency1 = np.median(latency_measurements)\nmedian_latency2_ms = 1000 * median_latency1\nprint(median_latency2_ms)\n","block_group":"6a88c6da97c841dfa90e462117c638fd","execution_count":37,"outputs":[{"name":"stdout","text":"11.198759078979492\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"55de39cca4fd4a5797cd8b15625eabbb","deepnote_cell_type":"text-cell-h1"},"source":"# LATENCY_PERCENTAGE_REDUCTION","block_group":"7d2612e615074d4a9fa871d1cc5ee33a"},{"cell_type":"code","metadata":{"source_hash":"1f8e3b68","execution_start":1704341065042,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"8362eb5564414174a33f60ccd5f5f9ce","deepnote_cell_type":"code"},"source":"# Calculate percentage reduction in latency\nLATENCY_PERCENTAGE_REDUCTION = 100 * (median_latency_ms - median_latency2_ms) / median_latency_ms\nprint(LATENCY_PERCENTAGE_REDUCTION)\n","block_group":"feb73512169e43278f0a850804eed179","execution_count":38,"outputs":[{"name":"stdout","text":"59.837712585397554\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=38c11a1c-cd40-4740-9cf4-b8aa568707a4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"2a41110c04d74b0a9248cc9c486c0033","deepnote_execution_queue":[]}}